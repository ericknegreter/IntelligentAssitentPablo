package com.oligo.t4.demoai_2;import android.Manifest;import android.app.Activity;import android.app.ActivityManager;import android.content.Context;import android.content.Intent;import android.content.pm.PackageManager;import android.graphics.Bitmap;import android.graphics.Point;import android.graphics.SurfaceTexture;import android.media.MediaPlayer;import android.net.Uri;import android.os.Build;import android.os.Bundle;import android.os.Environment;import android.os.Handler;import android.os.HandlerThread;import android.support.annotation.Nullable;import android.support.design.widget.FloatingActionButton;import android.support.design.widget.Snackbar;import android.support.v4.app.ActivityCompat;import android.support.v4.content.ContextCompat;import android.support.v4.content.FileProvider;import android.support.v7.app.AlertDialog;import android.support.v7.app.AppCompatActivity;import android.util.Log;import android.view.Gravity;import android.view.PixelCopy;import android.view.View;import android.widget.ImageView;import android.widget.Toast;import com.google.ar.core.Anchor;import com.google.ar.core.Frame;import com.google.ar.core.HitResult;import com.google.ar.core.Plane;import com.google.ar.core.Trackable;import com.google.ar.core.TrackingState;import com.google.ar.sceneform.AnchorNode;import com.google.ar.sceneform.ArSceneView;import com.google.ar.sceneform.FrameTime;import com.google.ar.sceneform.Node;import com.google.ar.sceneform.math.Vector3;import com.google.ar.sceneform.rendering.Color;import com.google.ar.sceneform.rendering.ExternalTexture;import com.google.ar.sceneform.rendering.ModelRenderable;import com.google.ar.sceneform.ux.ArFragment;import com.google.ar.sceneform.ux.TransformableNode;import java.io.ByteArrayOutputStream;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.List;import java.util.function.Consumer;import java.util.function.Function;import static android.content.Intent.FLAG_ACTIVITY_REORDER_TO_FRONT;public class camarablackstar2 extends AppCompatActivity {    private boolean isTracking;    private boolean isHitting;    private static final String TAG = camarablackstar2.class.getSimpleName ();    private static final double MIN_OPENGL_VERSION = 3.0;    private ArFragment arFragment;      @Nullable    private ModelRenderable videoRenderable;    public MediaPlayer mediaPlayer;    private FloatingActionButton btn_mas, btn_regresar; //Botones flotantes    ImageView tutorial;    private static final Color CHROMA_KEY_COLOR = new Color (1f, 1f, 1f);    private static final Color CHROMA_KEY_COLOR3 = new Color(0.3568627450980392f, 0.6392156862745098f, 0.098f);    private static final float VIDEO_HEIGHT_METERS = 0.75f;    private static final Color CHROMA_KEY_COLOR_2 = new Color (0.50980392156f, 0.50980392156f, 0.1333333333333333f);    // Controls the height of the video in world space.   // private static final float VIDEO_HEIGHT_METERS = 0.58f;    @SuppressWarnings({"AndroidApiChecker", "FutureReturnValueIgnored"})    // CompletableFuture requires api level 24            // FutureReturnValueIgnored is not valid    String equipo;    boolean flagB = true;    FloatingActionButton camera;   // boolean flagL= true;    boolean flagH = true;    boolean flagR= true;    boolean flag = true;    boolean ban2=true;    private static final int PERMISSION_REQUEST_CODE = 100;    private Handler manejador=new Handler();    FloatingActionButton fab2;    FloatingActionButton return_fab;    @Override    @SuppressWarnings({"AndroidApiChecker", "FutureReturnValueIgnored"})    public void onCreate(Bundle savedInstanceState) {        super.onCreate (savedInstanceState);        Intent new_intent = getIntent ();        if (!checkIsSupportedDeviceOrFinish (this)) {            return;        }        int seg=10000;        tutorial=(ImageView)findViewById (R.id.tutorial);        setContentView (R.layout.camarablackstar);        arFragment = (ArFragment) getSupportFragmentManager ().findFragmentById (R.id.sceneform_fragment);        equipo = new_intent.getStringExtra ("dispositivo");        btn_mas = (FloatingActionButton) findViewById (R.id.add);        fab2=(FloatingActionButton) findViewById (R.id.fab_howto2);        camera=(FloatingActionButton)findViewById(R.id.btnPhoto);        tutorial=(ImageView)findViewById (R.id.tutorial);        //Ocultar tutorial cuando se de clic en imagen        tutorial.setOnClickListener (new View.OnClickListener () {            @Override            public void onClick(View v) {                if(ban2==true){                    tutorial.setVisibility (View.VISIBLE);                    ban2=false;                }                else{                    tutorial.setVisibility (View.INVISIBLE);                    ban2=true;                }            }        });        return_fab=(FloatingActionButton)findViewById(R.id.retun);        //Ocultar la imagen en cierto tiempo de 10 segundos       /*  manejador.postDelayed(new Runnable() {            @Override            public void run() {                if(seg>3000) {                    tutorial.setVisibility (View.INVISIBLE);                }                else{tutorial.setVisibility (View.VISIBLE);                }            }        },seg);*/         fab2.setOnClickListener (new View.OnClickListener () {            @Override            public void onClick(View v) {                if(ban2==true){                    tutorial.setVisibility (View.VISIBLE);                    ban2=false;                }                else{                    tutorial.setVisibility (View.INVISIBLE);                    ban2=true;                }            }        });        btn_mas.hide ();        return_fab.setOnClickListener(new View.OnClickListener() {            @Override            public void onClick(View v) {                Intent regresar_intent=new Intent( getApplicationContext(),menu_p.class);                regresar_intent.setFlags(FLAG_ACTIVITY_REORDER_TO_FRONT);                startActivity(regresar_intent);            }        });        camera.setOnClickListener(view -> takePhoto());        ExternalTexture texture = new ExternalTexture ();        arFragment.getArSceneView ().getScene ().addOnUpdateListener (this::onUpdateFrame);        if(checkPermission())        {            camera.setEnabled(true);        }        else            {                requestPermission();            }        btn_mas.setOnClickListener (new View.OnClickListener () {            @Override            public void onClick(View v) {                mediaPlayer = MediaPlayer.create (camarablackstar2.this, R.raw.video_guanajuato_4444);                mediaPlayer.setSurface (texture.getSurface ());                mediaPlayer.setLooping(true);                addVideo (mediaPlayer, texture);            }        });    }    private void onUpdateFrame(FrameTime frameTime) {        Frame frame = arFragment.getArSceneView ().getArFrame ();        //int x=arFragment.getArSceneView().        // If there is no frame or ARCore is not tracking yet, just return.        Point point = getScreenCenter ();        List<HitResult> hits = frame.hitTest ((float) point.x, (float) point.y);        if ( frame.getCamera ().getTrackingState () != TrackingState.TRACKING) {            btn_mas.hide ();            return;        } else {            btn_mas.show ();            return;        }    }    public void addVideo(MediaPlayer mediaPlayer, ExternalTexture texture) {        // Create a renderable with a material that has a parameter of type 'samplerExternal' so that        // it can display an ExternalTexture. The material also has an implementation of a chroma key        Frame frame = arFragment.getArSceneView ().getArFrame ();        Point point = getScreenCenter ();        if (frame != null) {            List<HitResult> hits = frame.hitTest ((float) point.x, (float) point.y);            for (int i = 0; i < hits.size (); i++) {                Trackable trackable = hits.get (i).getTrackable ();                if (trackable instanceof Plane && ((Plane) trackable).isPoseInPolygon (hits.get (i).getHitPose ())) {                    placeObject (arFragment, hits.get (i).createAnchor (), mediaPlayer, texture);                }            }        }    }    private void addObject(Uri parse) {        Frame frame = arFragment.getArSceneView ().getArFrame ();        Point point = getScreenCenter ();        if (frame != null) {            List<HitResult> hits = frame.hitTest ((float) point.x, (float) point.y);            for (int i = 0; i < hits.size (); i++) {                Trackable trackable = hits.get (i).getTrackable ();                if (trackable instanceof Plane && ((Plane) trackable).isPoseInPolygon (hits.get (i).getHitPose ())) {                    placeObject3D (arFragment, hits.get (i).createAnchor (), parse);                    // hits.get(i).createAnchor()                }            }        }    }//Esta funcion es para    private final void placeObject3D(final ArFragment fragment, final Anchor createAnchor, Uri model) {        ModelRenderable.builder ().setSource (fragment.getContext (), model).build ().thenAccept ((new Consumer () {            // $FF: synthetic method            // $FF: bridge method            public void accept(Object var1) {                this.accept ((ModelRenderable) var1);            }            public final void accept(ModelRenderable it) {                if (it != null)                    camarablackstar2.this.addNode (arFragment, createAnchor, it);            }        })).exceptionally ((new Function () {            public Object apply(Object var1) {                return this.apply ((Throwable) var1);            }            @Nullable            public final Void apply(Throwable it) {                AlertDialog.Builder builder = new AlertDialog.Builder (camarablackstar2.this);                builder.setMessage (it.getMessage ()).setTitle ("error!");                AlertDialog dialog = builder.create ();                dialog.show ();                return null;            }        }));    }//En esta función agregar el fragment y el video a rederizar    private final void placeObject(final ArFragment arFragment, final Anchor createAnchor, MediaPlayer mediaPlayer, ExternalTexture texture) {        ModelRenderable.builder ()                .setSource (this, R.raw.chroma_key_video)                .build ()                .thenAccept (                        renderable -> {                            videoRenderable = renderable;                            renderable.getMaterial ().setExternalTexture ("videoTexture", texture);                            renderable.getMaterial ().setFloat4 ("keyColor", CHROMA_KEY_COLOR);                        })                .exceptionally (                        throwable -> {                            Toast toast =                                    Toast.makeText (this, "Unable to load video renderable", Toast.LENGTH_LONG);                            toast.setGravity (Gravity.CENTER, 0, 0);                            toast.show ();                            return null;                        });        Frame frame = arFragment.getArSceneView ().getArFrame ();        Point point = getScreenCenter ();        if (frame != null) {            List<HitResult> hits = frame.hitTest ((float) point.x, (float) point.y);            for (int i = 0; i < hits.size (); i++) {                Trackable trackable = hits.get (i).getTrackable ();                if (trackable instanceof Plane && ((Plane) trackable).isPoseInPolygon (hits.get (i).getHitPose ())) {                    //placeObject(arFragment, hits.get(i).createAnchor(), parse);                    // hits.get(i).createAnchor()                    Anchor anchor = hits.get (i).createAnchor ();                    AnchorNode anchorNode = new AnchorNode (anchor);                    addNode (arFragment, anchor, videoRenderable);                    anchorNode.setParent (arFragment.getArSceneView ().getScene ());                    // a node to render the video and add it to the anchor.                    Node videoNode = new Node ();                    videoNode.setParent (anchorNode);                    //  Set the scale of the node so that the aspect ratio of the video is correct.                    //   return new android.graphics.Point (vw.getWidth () / 2, vw.getHeight () / 2);                    float videoWidth = mediaPlayer.getVideoWidth ();                    float videoHeight = mediaPlayer.getVideoHeight ();                    videoNode.setLocalScale (                            new Vector3 (                                    VIDEO_HEIGHT_METERS * (videoWidth / videoHeight), VIDEO_HEIGHT_METERS, 1.0f));                    // Start playing the video when the first node is placed.                    if (!mediaPlayer.isPlaying ()) {                        mediaPlayer.start ();                        flagB = false;                       // flagL= false;                        flagH =false;                        flagR= false;                        flag = false;                        // Wait to set the renderable until the first frame of the  video becomes available.                        // This prevents the renderable from briefly appearing as a black quad before the video                        // plays.                        texture                                .getSurfaceTexture ()                                .setOnFrameAvailableListener (                                        (SurfaceTexture surfaceTexture) -> {                                            videoNode.setRenderable (videoRenderable);                                            texture.getSurfaceTexture ().setOnFrameAvailableListener (null);                                        });                    } else {                        videoNode.setRenderable (videoRenderable);                    }                }            }        }    }//Añade un en la esena el nodo    private void addNode(ArFragment fragment, Anchor createAnchor, ModelRenderable renderable) {        AnchorNode anchorNode = new AnchorNode (createAnchor);        TransformableNode transformableNode = new TransformableNode (fragment.getTransformationSystem ());        transformableNode.setRenderable (renderable);        transformableNode.setParent (anchorNode);        fragment.getArSceneView ().getScene ().addChild (anchorNode);        transformableNode.select ();        flagB = false;        //flagL= false;        flagH =false;        flagR= false;        flag = false;    }//Obtiene el punto central de la esena    private Point getScreenCenter() {        View vw = findViewById (android.R.id.content);        return new Point (vw.getWidth () / 2, vw.getHeight () / 2);    }    //Está funcion es para regresar    @Override    public void onBackPressed() {        if (mediaPlayer != null) {            mediaPlayer.stop ();        }       else {            Intent sent = new Intent (getApplicationContext (), menu_p.class);            startActivity (sent);       }    }    private void requestPermissions()    {    }    public static boolean checkIsSupportedDeviceOrFinish(final Activity activity) {        if (Build.VERSION.SDK_INT < Build.VERSION_CODES.N) {            Log.e (TAG, "Sceneform requires Android N or later");            Toast.makeText (activity, "Sceneform requires Android N or later", Toast.LENGTH_LONG).show ();            activity.finish ();            return false;        }        String openGlVersionString =                ((ActivityManager) activity.getSystemService (Context.ACTIVITY_SERVICE))                        .getDeviceConfigurationInfo ()                        .getGlEsVersion ();        if (Double.parseDouble (openGlVersionString) < MIN_OPENGL_VERSION) {            Log.e (TAG, "Sceneform requires OpenGL ES 3.0 later");            Toast.makeText (activity, "Sceneform requires OpenGL ES 3.0 or later", Toast.LENGTH_LONG)                    .show ();            activity.finish ();            return false;        }        return true;    }    private String generateFilename() {        String date =                new SimpleDateFormat("yyyyMMddHHmmss", java.util.Locale.getDefault()).format(new Date());        return Environment.getExternalStoragePublicDirectory(                Environment.DIRECTORY_PICTURES) + File.separator  + date + "_screenshot.jepg";    }    private void saveBitmapToDisk(Bitmap bitmap, String filename) throws IOException {        File out = new File(filename);        if (!out.getParentFile().exists()) {            out.getParentFile().mkdirs();        }        try (FileOutputStream outputStream = new FileOutputStream(filename);             ByteArrayOutputStream outputData = new ByteArrayOutputStream()) {            bitmap.compress(Bitmap.CompressFormat.PNG, 100, outputData);            outputData.writeTo(outputStream);            outputStream.flush();            outputStream.close();        } catch (IOException ex) {            throw new IOException("Failed to save bitmap to disk", ex);        }    }    private void takePhoto() {        final String filename = generateFilename();        ArSceneView view = arFragment.getArSceneView();        // Create a bitmap the size of the scene view.        final Bitmap bitmap = Bitmap.createBitmap(view.getWidth(), view.getHeight(),                Bitmap.Config.ARGB_8888);        // Create a handler thread to offload the processing of the image.        final HandlerThread handlerThread = new HandlerThread("PixelCopier");        handlerThread.start();        // Make the request to copy.        PixelCopy.request(view, bitmap, (copyResult) -> {            if (copyResult == PixelCopy.SUCCESS) {                try {                    saveBitmapToDisk(bitmap, filename);                } catch (IOException e) {                    Toast toast = Toast.makeText(camarablackstar2.this, e.toString(),                            Toast.LENGTH_LONG);                    toast.show();                    return;                }                Snackbar snackbar = Snackbar.make(findViewById(android.R.id.content),                        "Photo saved", Snackbar.LENGTH_LONG);                snackbar.setAction("Open in Photos", v -> {                    File photoFile = new File(filename);                    Uri photoURI = FileProvider.getUriForFile(camarablackstar2.this,                            camarablackstar2.this.getPackageName() + ".ar.codelab.name.provider",                            photoFile);                    Intent intent = new Intent(Intent.ACTION_VIEW, photoURI);                    intent.setDataAndType(photoURI, "image/*");                    intent.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION);                    startActivity(intent);                });                snackbar.show();            } else {                Toast toast = Toast.makeText(camarablackstar2.this,                        "Failed to copyPixels: " + copyResult, Toast.LENGTH_LONG);                toast.show();            }            handlerThread.quitSafely();        }, new Handler(handlerThread.getLooper()));    }    private boolean checkPermission() {        int result = ContextCompat.checkSelfPermission(camarablackstar2.this, Manifest.permission.WRITE_EXTERNAL_STORAGE);        if (result == PackageManager.PERMISSION_GRANTED) {            return true;        } else {            return false;        }    }    private void requestPermission() {        if (ActivityCompat.shouldShowRequestPermissionRationale(camarablackstar2.this, Manifest.permission.WRITE_EXTERNAL_STORAGE)) {            Toast.makeText(camarablackstar2.this, "Write External Storage permission allows us to save files. Please allow this permission in App Settings.", Toast.LENGTH_LONG).show();        } else {            ActivityCompat.requestPermissions(camarablackstar2.this, new String[]{Manifest.permission.WRITE_EXTERNAL_STORAGE}, PERMISSION_REQUEST_CODE);        }    }    @Override    public void onRequestPermissionsResult(int requestCode, String permissions[], int[] grantResults) {        switch (requestCode) {            case PERMISSION_REQUEST_CODE:                if (grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {                Log.e("value", "Permission Granted, Now you can use local drive .");                camera.setEnabled(true);            } else {                Log.e("value", "Permission Denied, You cannot use local drive .");                camera.setEnabled(false);            }            break;        }    }}